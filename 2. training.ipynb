{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cv2 import cv2\n",
    "from tqdm import tqdm, trange\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(4439, 3)\n"
    }
   ],
   "source": [
    "data = pd.read_csv('data/labeled/data_resized.csv')\n",
    "classes = data['name']\n",
    "path = data['path']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = stratSplit.split(path, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in splitted:\n",
    "    x_train = path[train_idx]\n",
    "    x_test = path[test_idx]\n",
    "    y_train = classes[train_idx]\n",
    "    y_test = classes[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(3551,) (888,) (3551,) (888,)\n"
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, x):\n",
    "    x = x.astype('float32')\n",
    "    mean, std = x.mean(), x.std()\n",
    "    x = (x - mean) / std\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y = model.predict(x)\n",
    "    return y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nC:\\ProgramData\\Anaconda3\\envs\\TA\\lib\\site-packages\\keras\\engine\\saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n  warnings.warn('No training configuration found in save file: '\n"
    }
   ],
   "source": [
    "model = load_model('model/facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "_________________\nBlock8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n__________________________________________________________________________________________________\nBlock8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n__________________________________________________________________________________________________\nBlock8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n__________________________________________________________________________________________________\nBlock8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n__________________________________________________________________________________________________\nBlock8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n__________________________________________________________________________________________________\nBlock8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n__________________________________________________________________________________________________\nBlock8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n__________________________________________________________________________________________________\nBlock8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n__________________________________________________________________________________________________\nBlock8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n__________________________________________________________________________________________________\nBlock8_1_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n                                                                 Block8_1_Conv2d_1x1[0][0]        \n__________________________________________________________________________________________________\nBlock8_1_Activation (Activation (None, 3, 3, 1792)   0           Block8_1_ScaleSum[0][0]          \n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n__________________________________________________________________________________________________\nBlock8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n__________________________________________________________________________________________________\nBlock8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n__________________________________________________________________________________________________\nBlock8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n__________________________________________________________________________________________________\nBlock8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n__________________________________________________________________________________________________\nBlock8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n__________________________________________________________________________________________________\nBlock8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n__________________________________________________________________________________________________\nBlock8_2_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n                                                                 Block8_2_Conv2d_1x1[0][0]        \n__________________________________________________________________________________________________\nBlock8_2_Activation (Activation (None, 3, 3, 1792)   0           Block8_2_ScaleSum[0][0]          \n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n__________________________________________________________________________________________________\nBlock8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n__________________________________________________________________________________________________\nBlock8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n__________________________________________________________________________________________________\nBlock8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n__________________________________________________________________________________________________\nBlock8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n__________________________________________________________________________________________________\nBlock8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n__________________________________________________________________________________________________\nBlock8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n__________________________________________________________________________________________________\nBlock8_3_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n                                                                 Block8_3_Conv2d_1x1[0][0]        \n__________________________________________________________________________________________________\nBlock8_3_Activation (Activation (None, 3, 3, 1792)   0           Block8_3_ScaleSum[0][0]          \n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n__________________________________________________________________________________________________\nBlock8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n__________________________________________________________________________________________________\nBlock8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n__________________________________________________________________________________________________\nBlock8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n__________________________________________________________________________________________________\nBlock8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n__________________________________________________________________________________________________\nBlock8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n__________________________________________________________________________________________________\nBlock8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n__________________________________________________________________________________________________\nBlock8_4_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n                                                                 Block8_4_Conv2d_1x1[0][0]        \n__________________________________________________________________________________________________\nBlock8_4_Activation (Activation (None, 3, 3, 1792)   0           Block8_4_ScaleSum[0][0]          \n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n__________________________________________________________________________________________________\nBlock8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n__________________________________________________________________________________________________\nBlock8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n__________________________________________________________________________________________________\nBlock8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n__________________________________________________________________________________________________\nBlock8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n__________________________________________________________________________________________________\nBlock8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n__________________________________________________________________________________________________\nBlock8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n__________________________________________________________________________________________________\nBlock8_5_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n                                                                 Block8_5_Conv2d_1x1[0][0]        \n__________________________________________________________________________________________________\nBlock8_5_Activation (Activation (None, 3, 3, 1792)   0           Block8_5_ScaleSum[0][0]          \n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n__________________________________________________________________________________________________\nBlock8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n__________________________________________________________________________________________________\nBlock8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n__________________________________________________________________________________________________\nBlock8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n__________________________________________________________________________________________________\nBlock8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n__________________________________________________________________________________________________\nBlock8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n__________________________________________________________________________________________________\nBlock8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n__________________________________________________________________________________________________\nBlock8_6_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n                                                                 Block8_6_Conv2d_1x1[0][0]        \n__________________________________________________________________________________________________\nAvgPool (GlobalAveragePooling2D (None, 1792)         0           Block8_6_ScaleSum[0][0]          \n__________________________________________________________________________________________________\nDropout (Dropout)               (None, 1792)         0           AvgPool[0][0]                    \n__________________________________________________________________________________________________\nBottleneck (Dense)              (None, 128)          229376      Dropout[0][0]                    \n__________________________________________________________________________________________________\nBottleneck_BatchNorm (BatchNorm (None, 128)          384         Bottleneck[0][0]                 \n==================================================================================================\nTotal params: 22,808,144\nTrainable params: 22,779,312\nNon-trainable params: 28,832\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 3551/3551 [01:25<00:00, 41.30it/s]\n100%|██████████| 888/888 [00:20<00:00, 42.44it/s]\n"
    }
   ],
   "source": [
    "x_train_feature = []\n",
    "x_test_feature = []\n",
    "for item in tqdm(x_train):\n",
    "    image = cv2.imread(item)\n",
    "    feature = get_embedding(model, image)\n",
    "    x_train_feature.append(feature)\n",
    "for item in tqdm(x_test):\n",
    "    image = cv2.imread(item)\n",
    "    feature = get_embedding(model, image)\n",
    "    x_test_feature.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_feature = np.array(x_train_feature)\n",
    "x_test_feature = np.array(x_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(3551, 128) (888, 128)\n"
    }
   ],
   "source": [
    "print(x_train_feature.shape, x_test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_encoder = Normalizer(norm='l2')\n",
    "x_train_normalized = x_encoder.transform(x_train_feature)\n",
    "x_test_normalized = x_encoder.transform(x_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(3551, 128) (888, 128)\n"
    }
   ],
   "source": [
    "print(x_train_feature.shape, x_test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoder = LabelEncoder()\n",
    "y_encoder.fit(y_train)\n",
    "y_train_encoded = y_encoder.transform(y_train)\n",
    "y_test_encoded = y_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {}\n",
    "for i in range(len(y_encoder.classes_)):\n",
    "    encoding[i] = y_encoder.classes_[i]\n",
    "file = open('label_encoding.pkl', 'wb')\n",
    "pickle.dump(encoding, file, pickle.HIGHEST_PROTOCOL)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(3551,) (888,)\n[ 8 20 16 ...  1  1 16][ 8 13 13  7 13  7  7 18  4  1 20  7  1 13 16  4 13  4 20 18  1  2 18 13\n 22  8 22 13  4  1  6  6 18 13 17  7 20 20  7 19 16  8 17  8 18 13  9  1\n  1  9 17 20 20  4 13 13 12 20 18  7 13 13 17 20 13  1  4 16  1  1 13  1\n  1  4  7 18  6 17  6  7 13  4 18 16  1  1  6  1 16  7  4  8 13  4 23  1\n 20  6 22 13 18 13 16  6  6 17  4 22 24  6  6  4  4  6  4 18 13  6 16 13\n 16  6  6  1 23  6 13  4  6  1 17 20  1 16 19  1  6 16 13 13  6 17 17 16\n 20  1  6  6  7  4 16  6  9  9 22  1  7 14  7 24  6  7  6 16  8  7  1 13\n 13  4  6 13 17  4  7  6  8 17  8  6 18  6 17  6 23  1  1  1  1  6 16  4\n  6  4  6 16 19  6 13  7 17 17  6  6  7  9  6  7  6 17  4 23  7 18  6  6\n  4  1 13  6 24  9  7 13 18  6 16  2  4  8  4  7 17 13 16  4 17  4  4 16\n  8  6 17  1 13 13 13  4  9 16  6 20  1  4  1 16  6 16 13 18  9 13  6  1\n  1 17  6  8  1  2  4 13  4 18 13 13 13 11  6 17  8  4 17  4  4 13  7  6\n 13  9  6  6  1 20 19 16  7 17 20  9  4 13  6  6  6 16 11  6  7 20  6 13\n  6 19  1  6 24  6  8  4  4  1 13  8  3 23  6  1  9  4 17 13 16  6 17 13\n  7 18 13  8 13  1 16  1  6  6  4 16 13 16  6  4 13 16 17 17  1  1  1  6\n  4  6  6 13  7  4  8 18  6 18  1 17  1 19  4 16  6 22 17  6 12  1 17  6\n  7 13 17 20 22 20  4  8 13 17 16  6  7  9  4  4  4 18 13  8 13  6  6 20\n 13  7  1  7 13  1  6 18 18  6 11 18 13  7 22 16  1  4  1  6 13  1  6  6\n 20  4 18 16 17 22  6 18  6 22 21 13  7  6  1 13  8  6 13  4 13  1  7 19\n  7 13  8  6 13 20  6  1 13 17  4 17  6  6  6 13 16 16  1  7  6  4  9  4\n  1 16 18 13  1 13  7 17  6  7 16  6  4  1  6 16  7  6 13  8  6  6 13  6\n  6 17  4 16 13  6  7 16  4 19  1  4 20  6  9 13  4 12  4 18  7 13  1  4\n  6 14 17 18 13 16  1  4  8  3 13  8 18 13  5  6  7  9  7  8  4  1 13  1\n  6 16  1 13  6 11 23  6  1 18 18 17 18  6  4  1  4  8 13  7 20 13  1 13\n  7  7 13  4 22  1  7  6 17  4  6 16  1 13 20 13  7 17  4  4  7  1  1 16\n 13 17  6  6  6  9 18 20  6 13  6 17  7 18  9  6 13 13 13 17 17  6 13  8\n 20 17  4 23  7  4 16  1 22 20 13  8  1  6  4  7  6 17  1 16 13  6  4  1\n  1 13 16  8 13  7  8  6  6  4 13 20  7 13 16  7  6  9 13 17 22 17 13 13\n 13  6 17  6 17 13 13  7  6  1 13  1  1 17  8  6 18 13 13  6  7  1  6  1\n 13 17 20  6  4  8 22  6  6  4 16 13  7  4  8  1  1 16 13  1 16  1  8 15\n  6  1  4  1  1  1 22  6  7  1  6  7 13  4  7 16 13  6  4  6 19 17 20  1\n  1  6 19 13  1 13  9  1 20 16 18  6 13 13  6 19 13 13  7 13  1  1 18 16\n  8  8  8 18 16  6  1 18  6  4  6  7  1 13 17 13  6 13  6 22 13 13 17  8\n  1  6  1 20  1  4  0  6  1 18 16 13 10  6 13  8 22 13  4  4 13  1  1 17\n  6  1  6  6  4  6 22  9  1  7  7  9  6 13  2 17 16 18 17  6  4  6 13  1\n  9 13 20 13  8 13 22  8 20 19  9  6  6 20  1 18  9  1  9 17 13  2 17  5\n 13  6  7 13  1  7 18 16  4  0 13  1 13 20 13 13  6  6 13  1  1  4 16 16]\n"
    }
   ],
   "source": [
    "print(y_train_encoded.shape, y_test_encoded.shape)\n",
    "print(y_train_encoded, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[LibSVM]"
    },
    {
     "data": {
      "text/plain": "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='linear', max_iter=-1, probability=True, random_state=None,\n    shrinking=True, tol=0.001, verbose=True)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel='linear', probability=True, verbose=True)\n",
    "classifier.fit(x_train_normalized, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = classifier.predict(x_train_normalized)\n",
    "test_predict = classifier.predict(x_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = accuracy_score(y_train_encoded, train_predict)\n",
    "score_test = accuracy_score(y_test_encoded, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.9549422697831597\n0.9391891891891891\n"
    }
   ],
   "source": [
    "print(score_train)\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = classifier.predict_proba(x_test_normalized[1:2])\n",
    "b = classifier.predict(x_test_normalized[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model/classifier.pkl', 'wb')\n",
    "pickle.dump(classifier, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train_normalized.npy', x_train_normalized)\n",
    "np.save('y_train_encoded.npy', y_train_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}